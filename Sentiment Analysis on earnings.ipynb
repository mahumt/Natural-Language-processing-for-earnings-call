{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, glob, string\n",
    "import sys, os #, shutil\n",
    "import time, csv\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import messagebox\n",
    "root = tk.Tk()\n",
    "messagebox.showwarning(\"!\",\"\"\"\n",
    "                    Windows will popup throughout the program. \n",
    "                    Run the instructions.\n",
    "                    If the popup window remain, manually close them or the programm will not advance.\n",
    "                    Set aside a folder specifcally for Sentiment analysis.\n",
    "                    Make sure there are two sub-folders in the the said directory.\n",
    "                    \"default\" where you will store the .txt or .csv files for the analysis.\n",
    "                    And \"dic\" wwhere the financial dictionary will be downloaded and stored.\n",
    "                    Programs will not run if these sub-folders are not present.\n",
    "                \"\"\")\n",
    "root.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Mahum/Desktop/ALL/programming and automation/PYTHON/NLP\n"
     ]
    }
   ],
   "source": [
    "def browse_button():\n",
    "    # Allow user to select a directory and store it in global var\n",
    "    # called folder_path\n",
    "    \n",
    "    global folder_path\n",
    "    filename = filedialog.askdirectory()\n",
    "    folder_path.set(filename)\n",
    "    print(filename)\n",
    "    sourcePath = folder_path.get()\n",
    "    os.chdir(sourcePath)  # Provide the path here\n",
    "\n",
    "root = Tk()\n",
    "\n",
    "folder_path = StringVar()\n",
    "\n",
    "lbl1 = Label(master=root,textvariable=folder_path)\n",
    "lbl1.grid(row=0, column=1)\n",
    "\n",
    "buttonBrowse = Button(text=\"        Set directory folder       \", \n",
    "                      command = browse_button, bg = 'green',\n",
    "                      fg='white', font = ('helvetica', 12, 'bold'))\n",
    "buttonBrowse.grid(row=2, column=1)\n",
    "mainloop()\n",
    "\n",
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading dictionary from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the dictionary from Google Drive source\n",
    "# https://drive.google.com/file/d/12ECPJMxV2wSalXG8ykMmkpa1fq_ur0Rf/view\n",
    "# https://github.com/ndrplz/google-drive-downloader\n",
    "#pip install googledrivedownloader\n",
    "\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "\n",
    "gdd.download_file_from_google_drive(file_id='12ECPJMxV2wSalXG8ykMmkpa1fq_ur0Rf',\n",
    "                                    dest_path='dic\\MasterDictionary_2018.csv',\n",
    "                                    unzip=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Financial dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary loaded\n"
     ]
    }
   ],
   "source": [
    "#https://datatofish.com/import-csv-file-python-using-pandas/\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "root= tk.Tk()\n",
    "\n",
    "canvas1 = tk.Canvas(root, width = 300, height = 300, bg = 'lightsteelblue2', relief = 'raised')\n",
    "canvas1.pack()\n",
    "\n",
    "def getCSV ():\n",
    "    global df\n",
    "    global import_file_path\n",
    "    import_file_path = filedialog.askopenfilename()\n",
    "    df = pd.read_csv (import_file_path, header = 0)\n",
    "    if df is not None:\n",
    "        print(\"Dictionary loaded\")\n",
    "    else:\n",
    "        print (\"Dictionary not loaded\")\n",
    "browseButton_CSV = tk.Button(text = \"      Import Dictionary CSV File     \",\n",
    "                             command = getCSV, \n",
    "                             bg = 'green', \n",
    "                             fg = 'white', \n",
    "                             font = ('helvetica', 12, 'bold'))\n",
    "canvas1.create_window(150, 150, window=browseButton_CSV)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" The program outputs:\n",
    "   1.  File name,  File size (in bytes)\n",
    "   2.  Number of words (based on LM_MasterDictionary\n",
    "   3.  Proportion of positive words, negative words,  uncertainty words, litigious words,\n",
    "       modal-weak words, modal-moderate words, modal-strong words, constraining words, alphanumeric characters (a-z, A-Z),\n",
    "       digits (0-9), numbers (collections of digits), syllables, word length, Vocabulary \"\"\"\n",
    "import time\n",
    "\n",
    "def load_masterdictionary(file_path, print_flag=False, f_log=None, get_other=False):\n",
    "    _master_dictionary = {}\n",
    "    _sentiment_categories = ['negative', 'positive', 'uncertainty', 'litigious', 'constraining',\n",
    "                             'strong_modal', 'weak_modal']\n",
    "    # Dropped from nltk: A, I, S, T, DON, WILL, AGAINST  Added: AMONG,\n",
    "    _stopwords = ['ME', 'MY', 'MYSELF', 'WE', 'OUR', 'OURS', 'OURSELVES', 'YOU', 'YOUR', 'YOURS',\n",
    "                       'YOURSELF', 'YOURSELVES', 'HE', 'HIM', 'HIS', 'HIMSELF', 'SHE', 'HER', 'HERS', 'HERSELF',\n",
    "                       'IT', 'ITS', 'ITSELF', 'THEY', 'THEM', 'THEIR', 'THEIRS', 'THEMSELVES', 'WHAT', 'WHICH',\n",
    "                       'WHO', 'WHOM', 'THIS', 'THAT', 'THESE', 'THOSE', 'AM', 'IS', 'ARE', 'WAS', 'WERE', 'BE',\n",
    "                       'BEEN', 'BEING', 'HAVE', 'HAS', 'HAD', 'HAVING', 'DO', 'DOES', 'DID', 'DOING', 'AN',\n",
    "                       'THE', 'AND', 'BUT', 'IF', 'OR', 'BECAUSE', 'AS', 'UNTIL', 'WHILE', 'OF', 'AT', 'BY',\n",
    "                       'FOR', 'WITH', 'ABOUT', 'BETWEEN', 'INTO', 'THROUGH', 'DURING', 'BEFORE',\n",
    "                       'AFTER', 'ABOVE', 'BELOW', 'TO', 'FROM', 'UP', 'DOWN', 'IN', 'OUT', 'ON', 'OFF', 'OVER',\n",
    "                       'UNDER', 'AGAIN', 'FURTHER', 'THEN', 'ONCE', 'HERE', 'THERE', 'WHEN', 'WHERE', 'WHY',\n",
    "                       'HOW', 'ALL', 'ANY', 'BOTH', 'EACH', 'FEW', 'MORE', 'MOST', 'OTHER', 'SOME', 'SUCH',\n",
    "                       'NO', 'NOR', 'NOT', 'ONLY', 'OWN', 'SAME', 'SO', 'THAN', 'TOO', 'VERY', 'CAN',\n",
    "                       'JUST', 'SHOULD', 'NOW']\n",
    "\n",
    "    with open(file_path) as f:\n",
    "        _total_documents = 0\n",
    "        _md_header = f.readline()\n",
    "        for line in f:\n",
    "            cols = line.split(',')\n",
    "            _master_dictionary[cols[0]] = MasterDictionary(cols, _stopwords)\n",
    "            _total_documents += _master_dictionary[cols[0]].doc_count\n",
    "            if len(_master_dictionary) % 5000 == 0 and print_flag:\n",
    "                print('\\r ...Loading Master Dictionary' + ' {}'.format(len(_master_dictionary)), end='', flush=True)\n",
    "\n",
    "    if print_flag:\n",
    "        print('\\r', end='')  # clear line\n",
    "        print('\\nMaster Dictionary loaded from file: \\n  ' + file_path)\n",
    "        print('  {0:,} words loaded in master_dictionary.'.format(len(_master_dictionary)) + '\\n')\n",
    "\n",
    "    if f_log:\n",
    "        try:\n",
    "            f_log.write('\\n\\n  load_masterdictionary log:')\n",
    "            f_log.write('\\n    Master Dictionary loaded from file: \\n       ' + file_path)\n",
    "            f_log.write('\\n    {0:,} words loaded in master_dictionary.\\n'.format(len(_master_dictionary)))\n",
    "        except Exception as e:\n",
    "            print('Log file in load_masterdictionary is not available for writing')\n",
    "            print('Error = {0}'.format(e))\n",
    "\n",
    "    if get_other:\n",
    "        return _master_dictionary, _md_header, _sentiment_categories, _stopwords, _total_documents\n",
    "    else:\n",
    "        return _master_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentimentdictionaries(_master_dictionary, _sentiment_categories):\n",
    "\n",
    "    _sentiment_dictionary = {}\n",
    "    for category in _sentiment_categories:\n",
    "        _sentiment_dictionary[category] = {}\n",
    "    # Create dictionary of sentiment dictionaries with count set = 0\n",
    "    for word in _master_dictionary.keys():\n",
    "        for category in _sentiment_categories:\n",
    "            if _master_dictionary[word].sentiment[category]:\n",
    "                _sentiment_dictionary[category][word] = 0\n",
    "\n",
    "    return _sentiment_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MasterDictionary:\n",
    "    def __init__(self, cols, _stopwords):\n",
    "        self.word = cols[0].upper()\n",
    "        self.sequence_number = int(cols[1])\n",
    "        self.word_count = int(cols[2])\n",
    "        self.word_proportion = float(cols[3])\n",
    "        self.average_proportion = float(cols[4])\n",
    "        self.std_dev_prop = float(cols[5])\n",
    "        self.doc_count = int(cols[6])\n",
    "        self.negative = int(cols[7])\n",
    "        self.positive = int(cols[8])\n",
    "        self.uncertainty = int(cols[9])\n",
    "        self.litigious = int(cols[10])\n",
    "        self.constraining = int(cols[11])\n",
    "        self.superfluous = int(cols[12])\n",
    "        self.interesting = int(cols[13])\n",
    "        self.modal_number = int(cols[14])\n",
    "        self.strong_modal = False\n",
    "        if int(cols[14]) == 1:\n",
    "            self.strong_modal = True\n",
    "        self.moderate_modal = False\n",
    "        if int(cols[14]) == 2:\n",
    "            self.moderate_modal = True\n",
    "        self.weak_modal = False\n",
    "        if int(cols[14]) == 3:\n",
    "            self.weak_modal = True\n",
    "        self.sentiment = {}\n",
    "        self.sentiment['negative'] = bool(self.negative)\n",
    "        self.sentiment['positive'] = bool(self.positive)\n",
    "        self.sentiment['uncertainty'] = bool(self.uncertainty)\n",
    "        self.sentiment['litigious'] = bool(self.litigious)\n",
    "        self.sentiment['constraining'] = bool(self.constraining)\n",
    "        self.sentiment['strong_modal'] = bool(self.strong_modal)\n",
    "        self.sentiment['weak_modal'] = bool(self.weak_modal)\n",
    "        self.irregular_verb = int(cols[15])\n",
    "        self.harvard_iv = int(cols[16])\n",
    "        self.syllables = int(cols[17])\n",
    "        self.source = cols[18]\n",
    "\n",
    "        if self.word in _stopwords:\n",
    "            self.stopword = True\n",
    "        else:\n",
    "            self.stopword = False\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 13 03:40:51 2020/n\n",
      " ...Loading Master Dictionary 85000\n",
      "Master Dictionary loaded from file: \n",
      "  C:/Users/Mahum/Desktop/ALL/programming and automation/PYTHON/NLP/dic/MasterDictionary_2018.csv\n",
      "  86,486 words loaded in master_dictionary.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-151893695843>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%c'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmaster_dictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd_header\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentiment_categories\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstopwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_masterdictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimport_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'Normal termination.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%c'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(time.strftime('%c') + '/n')\n",
    "    master_dictionary, md_header, sentiment_categories, stopwords = load_masterdictionary(import_file_path, True, False, True)\n",
    "    print('\\n' + 'Normal termination.')\n",
    "    print(time.strftime('%c') + '/n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ...Loading Master Dictionary 85000\n",
      "Master Dictionary loaded from file: \n",
      "  C:/Users/Mahum/Desktop/ALL/programming and automation/PYTHON/NLP/dic/MasterDictionary_2018.csv\n",
      "  86,486 words loaded in master_dictionary.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm_dictionary = load_masterdictionary(import_file_path, True, False, False) #(MASTER_DICTIONARY_FILE, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_FILES = path + \"\\\\default\\\\*.*\"\n",
    "OUTPUT_FILE = path + \"\\\\results\\\\Parser.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FIELDS = ['file name,', 'file size,', 'number of words,', '% positive,', '% negative,',\n",
    "                 '% uncertainty,', '% litigious,', '% modal-weak,', '% modal moderate,', '% modal strong,',\n",
    "                 '% constraining,', '# of alphabetic,', '# of digits,', '# of numbers,', 'avg # of syllables per word,',\n",
    "                 'average word length,', 'vocabulary', 'KeywordCount']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counting(regex, boolean, file):\n",
    "    filename = os.path.basename(file)\n",
    "    (file_name, ext) = os.path.splitext(filename) \n",
    "    \n",
    "    print(\"Keyword count file:- \", file_name+ext )\n",
    "    if boolean == 'yes':\n",
    "        regex = input(\"Enter Keyword(s) Combination for counting: \")\n",
    "    \n",
    "    fin = open(file, 'r', encoding='UTF-8', errors='ignore') \n",
    "    doc = fin.read()\n",
    "    count_data = 0\n",
    "    count_data  = regex, len(re.compile(regex).findall(doc))\n",
    "    return count_data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(doc):\n",
    "\n",
    "    vdictionary     = {}\n",
    "    _odata          = [0] * 18 #change this 18 up or down if adding more data to output file\n",
    "    # https://www.youtube.com/watch?v=s1XiCh-mGCA&ab_channel=PrettyPrinted\n",
    "    # this passes a list, which is written as 18 columns using csv module\n",
    "    total_syllables = 0\n",
    "    word_length     = 0\n",
    "\n",
    "    tokens = re.findall('\\w+', doc)  # \\w+ splits hyphenated words\n",
    "    for token in tokens:\n",
    "        if not token.isdigit() and len(token) > 1 and token in lm_dictionary:\n",
    "            _odata[2]   += 1  # word count \n",
    "            word_length += len(token)\n",
    "            if token not in vdictionary:\n",
    "                vdictionary[token] = 1\n",
    "            if lm_dictionary[token].positive: _odata[3]       += 1  #positive words\n",
    "            if lm_dictionary[token].negative: _odata[4]       += 1  # negative words\n",
    "            if lm_dictionary[token].uncertainty: _odata[5]    += 1  # uncertain\n",
    "            if lm_dictionary[token].litigious: _odata[6]      += 1   #litigious \n",
    "            if lm_dictionary[token].weak_modal: _odata[7]     += 1   #weak modal words\n",
    "            if lm_dictionary[token].moderate_modal: _odata[8] += 1   #moderate modal\n",
    "            if lm_dictionary[token].strong_modal: _odata[9]   += 1   #strong modal\n",
    "            if lm_dictionary[token].constraining: _odata[10]  += 1   #constraining words\n",
    "            total_syllables += lm_dictionary[token].syllables  \n",
    "\n",
    "    _odata[11] = len(re.findall('[A-Z]', doc))  #total no of alphabets\n",
    "    _odata[12] = len(re.findall('[0-9]', doc))   #total no of digits\n",
    "    doc = re.sub('(?!=[0-9])(\\.|,)(?=[0-9])', '', doc)       # drop punctuation within numbers for number count\n",
    "    doc = doc.translate(str.maketrans(string.punctuation, \" \" * len(string.punctuation)))\n",
    "    _odata[13] = len(re.findall(r'\\b[-+\\(]?[$€£]?[-+(]?\\d+\\)?\\b', doc))   # no of punctions\n",
    "    _odata[14] = total_syllables / _odata[2]    #  avg no of syllables per word\n",
    "    _odata[15] = word_length / _odata[2]        #  average word length\n",
    "    _odata[16] = len(vdictionary)               #  vocabulary\n",
    "   \n",
    "    # Convert counts to %\n",
    "    for i in range(3, 11):\n",
    "           _odata[i] = (_odata[i] / _odata[2]) * 100\n",
    "        \n",
    "    return _odata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    import csv\n",
    "\n",
    "    boolean = input(\"Enter 'yes'if you want all files to have different keywords search/else 'no':\" )\n",
    "    regex = '..' #intialize variable, 'ghost' variable\n",
    "\n",
    "    if boolean == 'no':\n",
    "        regex = input(\"Enter Keyword(s) Combination for counting: \")\n",
    "        #regex = r1\n",
    "    \n",
    "    f_out = open(OUTPUT_FILE, 'w')\n",
    "    wr = csv.writer(f_out, lineterminator='\\n')\n",
    "    wr.writerow(OUTPUT_FIELDS)\n",
    "\n",
    "    file_list = glob.glob(TARGET_FILES)\n",
    "    for file in file_list:\n",
    "        #https://openwritings.net/pg/python/python-how-get-filename-without-extension\n",
    "        filename = os.path.basename(file)# Get the filename only from the initial file path.\n",
    "        (file_name, ext) = os.path.splitext(filename) # Use splitext() to get filename and extension separately.\n",
    "        \n",
    "        print(\"Main Function: \", file_name)\n",
    "        with open(file, 'r', encoding='UTF-8', errors='ignore') as f_in:\n",
    "           # print (f_in) \n",
    "            doc = f_in.read()\n",
    "            doc_len = len(doc)\n",
    "            doc = re.sub('(May|MAY)', ' ', doc)  # drop all May month references\n",
    "            doc = doc.upper()  #caps aren't informative so shift\n",
    "\n",
    "            output_data     =  get_data(doc)\n",
    "            output_data[0]  =  file_name + ext # to get the filename instead of the file path. if path needed change file_name to file\n",
    "            output_data[1]  =  doc_len  # column name filze size\n",
    "           # output_data[17] =  counting(regex, boolean)\n",
    "            \n",
    "            #the rest is from moeez :-\n",
    "           # print(\"main :- file \" , file)\n",
    "            output_data[17] =  counting(regex, boolean, file)\n",
    "\n",
    "            wr.writerow(output_data) \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example with same keyword being searched in multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tue Oct 13 03:41:05 2020\n",
      " Parser.py \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter 'yes'if you want all files to have different keywords search/else 'no': no\n",
      "Enter Keyword(s) Combination for counting:  review\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Function:  (IHRT)\n",
      "Keyword count file:-  (IHRT).txt\n",
      "Main Function:  BAC shareholders call\n",
      "Keyword count file:-  BAC shareholders call.pdf\n",
      "Main Function:  Christmas1\n",
      "Keyword count file:-  Christmas1.csv\n",
      "Main Function:  orchi bal sheet\n",
      "Keyword count file:-  orchi bal sheet.html\n",
      "Main Function:  Results1\n",
      "Keyword count file:-  Results1.xlsx\n",
      "\n",
      "Tue Oct 13 03:41:12 2020\n",
      "Normal termination.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file name,</th>\n",
       "      <th>file size,</th>\n",
       "      <th>number of words,</th>\n",
       "      <th>% positive,</th>\n",
       "      <th>% negative,</th>\n",
       "      <th>% uncertainty,</th>\n",
       "      <th>% litigious,</th>\n",
       "      <th>% modal-weak,</th>\n",
       "      <th>% modal moderate,</th>\n",
       "      <th>% modal strong,</th>\n",
       "      <th>% constraining,</th>\n",
       "      <th># of alphabetic,</th>\n",
       "      <th># of digits,</th>\n",
       "      <th># of numbers,</th>\n",
       "      <th>avg # of syllables per word,</th>\n",
       "      <th>average word length,</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>KeywordCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(IHRT).txt</td>\n",
       "      <td>52426</td>\n",
       "      <td>8698</td>\n",
       "      <td>1.873994</td>\n",
       "      <td>0.563348</td>\n",
       "      <td>0.528857</td>\n",
       "      <td>0.080478</td>\n",
       "      <td>0.149460</td>\n",
       "      <td>0.517360</td>\n",
       "      <td>0.494367</td>\n",
       "      <td>0.034491</td>\n",
       "      <td>40288</td>\n",
       "      <td>320</td>\n",
       "      <td>148</td>\n",
       "      <td>1.488618</td>\n",
       "      <td>4.371465</td>\n",
       "      <td>1172</td>\n",
       "      <td>('review', 7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BAC shareholders call.pdf</td>\n",
       "      <td>120332</td>\n",
       "      <td>1008</td>\n",
       "      <td>0.396825</td>\n",
       "      <td>0.099206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47644</td>\n",
       "      <td>14381</td>\n",
       "      <td>4273</td>\n",
       "      <td>1.453373</td>\n",
       "      <td>4.519841</td>\n",
       "      <td>175</td>\n",
       "      <td>('review', 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christmas1.csv</td>\n",
       "      <td>120480</td>\n",
       "      <td>18209</td>\n",
       "      <td>2.592125</td>\n",
       "      <td>0.730408</td>\n",
       "      <td>0.900654</td>\n",
       "      <td>0.043934</td>\n",
       "      <td>0.192213</td>\n",
       "      <td>0.291065</td>\n",
       "      <td>0.637048</td>\n",
       "      <td>0.131803</td>\n",
       "      <td>94271</td>\n",
       "      <td>2241</td>\n",
       "      <td>923</td>\n",
       "      <td>1.596134</td>\n",
       "      <td>4.942117</td>\n",
       "      <td>2188</td>\n",
       "      <td>('review', 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>orchi bal sheet.html</td>\n",
       "      <td>238744</td>\n",
       "      <td>9250</td>\n",
       "      <td>8.659459</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.627027</td>\n",
       "      <td>0.183784</td>\n",
       "      <td>0.151351</td>\n",
       "      <td>0.097297</td>\n",
       "      <td>0.129730</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>174955</td>\n",
       "      <td>4585</td>\n",
       "      <td>1802</td>\n",
       "      <td>1.463351</td>\n",
       "      <td>5.275568</td>\n",
       "      <td>953</td>\n",
       "      <td>('review', 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Results1.xlsx</td>\n",
       "      <td>18198</td>\n",
       "      <td>59</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6264</td>\n",
       "      <td>1074</td>\n",
       "      <td>268</td>\n",
       "      <td>1.220339</td>\n",
       "      <td>3.457627</td>\n",
       "      <td>41</td>\n",
       "      <td>('review', 0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  file name,  file size,  number of words,  % positive,  \\\n",
       "0                 (IHRT).txt       52426              8698     1.873994   \n",
       "1  BAC shareholders call.pdf      120332              1008     0.396825   \n",
       "2             Christmas1.csv      120480             18209     2.592125   \n",
       "3       orchi bal sheet.html      238744              9250     8.659459   \n",
       "4              Results1.xlsx       18198                59     0.000000   \n",
       "\n",
       "   % negative,  % uncertainty,  % litigious,  % modal-weak,  \\\n",
       "0     0.563348        0.528857      0.080478       0.149460   \n",
       "1     0.099206        0.000000      0.000000       0.000000   \n",
       "2     0.730408        0.900654      0.043934       0.192213   \n",
       "3     1.200000        0.627027      0.183784       0.151351   \n",
       "4     0.000000        0.000000      0.000000       0.000000   \n",
       "\n",
       "   % modal moderate,  % modal strong,  % constraining,  # of alphabetic,  \\\n",
       "0           0.517360         0.494367         0.034491             40288   \n",
       "1           0.000000         0.000000         0.000000             47644   \n",
       "2           0.291065         0.637048         0.131803             94271   \n",
       "3           0.097297         0.129730         0.162162            174955   \n",
       "4           0.000000         0.000000         0.000000              6264   \n",
       "\n",
       "   # of digits,  # of numbers,  avg # of syllables per word,  \\\n",
       "0           320            148                      1.488618   \n",
       "1         14381           4273                      1.453373   \n",
       "2          2241            923                      1.596134   \n",
       "3          4585           1802                      1.463351   \n",
       "4          1074            268                      1.220339   \n",
       "\n",
       "   average word length,  vocabulary   KeywordCount  \n",
       "0              4.371465        1172  ('review', 7)  \n",
       "1              4.519841         175  ('review', 0)  \n",
       "2              4.942117        2188  ('review', 3)  \n",
       "3              5.275568         953  ('review', 0)  \n",
       "4              3.457627          41  ('review', 0)  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print('\\n' + time.strftime('%c') + '\\n Parser.py \\n')\n",
    "    main()\n",
    "    print('\\n' + time.strftime('%c') + '\\nNormal termination.')\n",
    "    \n",
    "pd.read_csv(r'results\\Parser.csv', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example with different keywords being searched in multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tue Oct 13 03:41:26 2020\n",
      " Parser.py \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter 'yes'if you want all files to have different keywords search/else 'no': yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Function:  (IHRT)\n",
      "Keyword count file:-  (IHRT).txt\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Keyword(s) Combination for counting:  review\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Function:  BAC shareholders call\n",
      "Keyword count file:-  BAC shareholders call.pdf\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Keyword(s) Combination for counting:  quarter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Function:  Christmas1\n",
      "Keyword count file:-  Christmas1.csv\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Keyword(s) Combination for counting:  fiscal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Function:  orchi bal sheet\n",
      "Keyword count file:-  orchi bal sheet.html\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Keyword(s) Combination for counting:  performance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Function:  Results1\n",
      "Keyword count file:-  Results1.xlsx\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Keyword(s) Combination for counting:  result\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tue Oct 13 03:41:46 2020\n",
      "Normal termination.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file name,</th>\n",
       "      <th>file size,</th>\n",
       "      <th>number of words,</th>\n",
       "      <th>% positive,</th>\n",
       "      <th>% negative,</th>\n",
       "      <th>% uncertainty,</th>\n",
       "      <th>% litigious,</th>\n",
       "      <th>% modal-weak,</th>\n",
       "      <th>% modal moderate,</th>\n",
       "      <th>% modal strong,</th>\n",
       "      <th>% constraining,</th>\n",
       "      <th># of alphabetic,</th>\n",
       "      <th># of digits,</th>\n",
       "      <th># of numbers,</th>\n",
       "      <th>avg # of syllables per word,</th>\n",
       "      <th>average word length,</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>KeywordCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(IHRT).txt</td>\n",
       "      <td>52426</td>\n",
       "      <td>8698</td>\n",
       "      <td>1.873994</td>\n",
       "      <td>0.563348</td>\n",
       "      <td>0.528857</td>\n",
       "      <td>0.080478</td>\n",
       "      <td>0.149460</td>\n",
       "      <td>0.517360</td>\n",
       "      <td>0.494367</td>\n",
       "      <td>0.034491</td>\n",
       "      <td>40288</td>\n",
       "      <td>320</td>\n",
       "      <td>148</td>\n",
       "      <td>1.488618</td>\n",
       "      <td>4.371465</td>\n",
       "      <td>1172</td>\n",
       "      <td>('review', 7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BAC shareholders call.pdf</td>\n",
       "      <td>120332</td>\n",
       "      <td>1008</td>\n",
       "      <td>0.396825</td>\n",
       "      <td>0.099206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47644</td>\n",
       "      <td>14381</td>\n",
       "      <td>4273</td>\n",
       "      <td>1.453373</td>\n",
       "      <td>4.519841</td>\n",
       "      <td>175</td>\n",
       "      <td>('quarter', 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christmas1.csv</td>\n",
       "      <td>120480</td>\n",
       "      <td>18209</td>\n",
       "      <td>2.592125</td>\n",
       "      <td>0.730408</td>\n",
       "      <td>0.900654</td>\n",
       "      <td>0.043934</td>\n",
       "      <td>0.192213</td>\n",
       "      <td>0.291065</td>\n",
       "      <td>0.637048</td>\n",
       "      <td>0.131803</td>\n",
       "      <td>94271</td>\n",
       "      <td>2241</td>\n",
       "      <td>923</td>\n",
       "      <td>1.596134</td>\n",
       "      <td>4.942117</td>\n",
       "      <td>2188</td>\n",
       "      <td>('fiscal', 35)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>orchi bal sheet.html</td>\n",
       "      <td>238744</td>\n",
       "      <td>9250</td>\n",
       "      <td>8.659459</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.627027</td>\n",
       "      <td>0.183784</td>\n",
       "      <td>0.151351</td>\n",
       "      <td>0.097297</td>\n",
       "      <td>0.129730</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>174955</td>\n",
       "      <td>4585</td>\n",
       "      <td>1802</td>\n",
       "      <td>1.463351</td>\n",
       "      <td>5.275568</td>\n",
       "      <td>953</td>\n",
       "      <td>('performance', 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Results1.xlsx</td>\n",
       "      <td>18198</td>\n",
       "      <td>59</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6264</td>\n",
       "      <td>1074</td>\n",
       "      <td>268</td>\n",
       "      <td>1.220339</td>\n",
       "      <td>3.457627</td>\n",
       "      <td>41</td>\n",
       "      <td>('result', 0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  file name,  file size,  number of words,  % positive,  \\\n",
       "0                 (IHRT).txt       52426              8698     1.873994   \n",
       "1  BAC shareholders call.pdf      120332              1008     0.396825   \n",
       "2             Christmas1.csv      120480             18209     2.592125   \n",
       "3       orchi bal sheet.html      238744              9250     8.659459   \n",
       "4              Results1.xlsx       18198                59     0.000000   \n",
       "\n",
       "   % negative,  % uncertainty,  % litigious,  % modal-weak,  \\\n",
       "0     0.563348        0.528857      0.080478       0.149460   \n",
       "1     0.099206        0.000000      0.000000       0.000000   \n",
       "2     0.730408        0.900654      0.043934       0.192213   \n",
       "3     1.200000        0.627027      0.183784       0.151351   \n",
       "4     0.000000        0.000000      0.000000       0.000000   \n",
       "\n",
       "   % modal moderate,  % modal strong,  % constraining,  # of alphabetic,  \\\n",
       "0           0.517360         0.494367         0.034491             40288   \n",
       "1           0.000000         0.000000         0.000000             47644   \n",
       "2           0.291065         0.637048         0.131803             94271   \n",
       "3           0.097297         0.129730         0.162162            174955   \n",
       "4           0.000000         0.000000         0.000000              6264   \n",
       "\n",
       "   # of digits,  # of numbers,  avg # of syllables per word,  \\\n",
       "0           320            148                      1.488618   \n",
       "1         14381           4273                      1.453373   \n",
       "2          2241            923                      1.596134   \n",
       "3          4585           1802                      1.463351   \n",
       "4          1074            268                      1.220339   \n",
       "\n",
       "   average word length,  vocabulary        KeywordCount  \n",
       "0              4.371465        1172       ('review', 7)  \n",
       "1              4.519841         175      ('quarter', 0)  \n",
       "2              4.942117        2188      ('fiscal', 35)  \n",
       "3              5.275568         953  ('performance', 1)  \n",
       "4              3.457627          41       ('result', 0)  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print('\\n' + time.strftime('%c') + '\\n Parser.py \\n')\n",
    "    main()\n",
    "    print('\\n' + time.strftime('%c') + '\\nNormal termination.')\n",
    "    \n",
    "pd.read_csv(r'results\\Parser.csv', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
